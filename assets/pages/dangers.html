<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="../css/dangers.css">
    <link rel="stylesheet" href="../css/index.css">
</head>
<body>
    <div class="header">
        <div class="banner">
            <div class="title"><h1>Projekt-AI</h1></div>
        </div>
   </div>

    <nav class="navbar">
        <div class="navbar">
            <ul>
                <li><a href="./Accueil.html"><button class="nav_button">Accueil</button></a></li>
                <li><a href="./dangers.html"><button class="nav_button">Les dangers de l'IA</button></a></li>
                <li><a href="./futur.html"><button class="nav_button">Le futur de l'IA</button></a></li>
                <li><a href="./pop.html"><button class="nav_button">L'IA sur la Pop Culture</button></a></li>
                <li><a href="./fonctions.html"><button class="nav_button">Les fonctions de l'IA</button></a></li>
            </ul>
        </div>
    </nav>

    <div class="paragraphe1">
        <img id="Dangers_1" src="../img/Dangers_1.jpg" alt="Danger_1">
        <p>
            Geoffrey Hinton, pionnier de l'intelligence artificielle, a démissionné lundi 1er mai 2023 de Google après 10 ans au service du géant américain. Dans une interview accordée au New York Times, il révèle être parti pour parler librement de l'IA générative comme ChatGPT, sans que cela n'impacte l'entreprise. Il exprime ses regrets concernant son implication dans le développement de cette dernière et se console tant bien que mal « avec cette excuse commune : si je ne l'avais pas fait, quelqu'un d'autre l'aurait fait ».
        </p>
        <p>
            Repenti, il revient sur les dangers de l'IA dans son interview au New York Times, qui représenterait selon lui « de graves risques pour la société et l'humanité ». Voici ses cinq plus grandes craintes.
        </p>
    </div>

    <div class="paragraphe2">
        <img id="Dangers_2" src="../img/Dangers_2.jpg" alt="Dangers_2">
        <p><strong>Quand la machine dépasse son créateur</strong></p>
        <p>
            La vitesse à laquelle les avancées s'enchaînent a dépassé les attentes des .Jusqu'à l'année dernière, il n'estimait pas ces progrès dangereux, mais son point de vue a changé lorsque Google et OpenAI ont développé des systèmes neuronaux capables de traiter des quantités de données très importantes, et pouvant rendre ces systèmes plus performants que le cerveau humain, et donc très dangereux.
        </p>
        <p><strong>Des suppressions d'emplois tous azimuts</strong></p>
        <p>
            D'un point de vue économique, le parrain de l'IA craint que cette technologie puisse drastiquement perturber le marché du travail. « L'IA supprime le travail pénible », a-t-il déclaré, avant d'ajouter qu'« elle pourrait supprimer bien plus que cela », touchant notamment les traducteurs et les assistants personnels. Une suppression d'emploi qui n'épargnera pas les plus « intelligents », malgré ce que beaucoup pense, estimant être à l'abri.
        </p>  
        <p><strong>La menace de « robots meurtriers »</strong></p>
        <p>
            Celui qui a été le professeur d'Ilya Sutskever – l'actuel directeur scientifique d'OpenAI – juge les progrès technologiques trop rapides, comparés aux moyens dont nous disposons pour réguler l'usage de l'IA. « Je ne pense pas qu'il faille l'accélérer tant qu'on n'a pas compris si on pouvait la contrôler », affirme le chercheur. Il craint que des versions futures deviennent des « menaces pour l'humanité ». Selon lui, les futures IA seraient capables de développer des comportements inattendus après avoir analysé un grand nombre de données. Ceci est rendu possible car les systèmes d'IA génèrent leur propre code et le dirigent… ce qui pourrait les transformer en « armes autonomes » et « robots meurtriers », même si de nombreux experts relativisent cette menace.
        </p>
    </div>

    <div class="paragraphe3">
        <img id="Dangers_3" src="../img/Dangers_3.jpg" alt="Dangers_3">
        <p><strong>L'IA aux mains d'acteurs malveillants</strong></p>
        <p>
            Selon lui, la menace vient aussi du mauvais usage de l'IA par des acteurs dangereux. Il est « difficile de trouver comment empêcher les mauvais acteurs de l'utiliser pour des fins malveillantes », s'inquiète-t-il. Geoffrey Hinton est notamment opposé à l'usage de l'intelligence artificielle dans le domaine militaire. Il craint particulièrement le développement de « soldats robots » par les humains. Dans les années 1980, il avait même décidé de quitter l'université de Carnegie Mellon, aux États-Unis, parce que ses recherches y étaient financées par le Pentagone.
        </p>
        <p><strong>« Générateur de conneries »</strong></p>
        <p>
            Dernière menace, et pas des moindres : celle de la désinformation liée à l'IA. Cette effervescence scientifique, adjointe à l'utilisation massive de l'IA, rendra presque impossible la capacité à discerner « ce qui est vrai de ce qui ne l'est plus ». Le scientifique parle même de « générateur de conneries ». Une expression qui désigne la capacité de l'IA à produire, de manière persuasive, des déclarations qui semblent plausibles sans pour autant être vraies.
        </p>
        <p><strong>Alors quelle solution ?</strong></p>
        <p>
            L'expert en réseaux neuronaux préconise une régulation interplanétaire, mais il reste lucide : « Cela risque d'être impossible […]. Tout comme pour les armes nucléaires, il n'y a aucun moyen pour savoir si les compagnies ou les pays y travaillent en secret. Le seul espoir est que les plus grands scientifiques du monde travaillent main dans la main afin de trouver des solutions pour contrôler l'IA. »
        </p>
    </div>

    <footer class="footer">
        <div class="footer_content">
            <ul>
                <li><a href="./Contact.html"><button class="footer_button">Contact</button></a></li>
                <li><a href="./About.html"><button class="footer_button">A Propos</button></a></li>
                <div class="social_media">
                    <img src="./assets/img/Instagram_icon.png" width="35px" alt="insta">
                    <img src="./assets/img/LinkedIn_logo_initials.png" width="35px" alt="Linkedin">
                    <img src="./assets/img/Twitter-logo.png" width="38px" alt="Twitter">
                </div>
            </ul>
        </div> 
    </footer>
</body>
</html>